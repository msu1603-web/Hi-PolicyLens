import streamlit as st
import requests
from pypdf import PdfReader
from sentence_transformers import SentenceTransformer
import chromadb
import uuid # ê³ ìœ  ID ìƒì„±ì„ ìœ„í•´ ì¶”ê°€

# --- 1. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---

# PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

# í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„(ì²­í¬)ë¡œ ë‚˜ëˆ„ëŠ” í•¨ìˆ˜
def get_text_chunks(text):
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•˜ê²Œ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    # ë” ì •êµí•˜ê²Œ ë‚˜ëˆ„ë ¤ë©´ LangChain ê°™ì€ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    chunks = text.split('\n\n')
    return [chunk for chunk in chunks if chunk.strip()] # ë‚´ìš©ì´ ìˆëŠ” ì²­í¬ë§Œ ë°˜í™˜

# ì²­í¬ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def get_vectorstore(text_chunks):
    # ë¬´ë£Œ ê³µê°œëœ í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    # ì´ ëª¨ë¸ì´ ë¬¸ì¥ì˜ 'ì˜ë¯¸'ë¥¼ ìˆ«ìì˜ ë°°ì—´(ë²¡í„°)ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.
    model = SentenceTransformer('jhgan/ko-sroberta-multitask')

    # ChromaDB í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ë©”ëª¨ë¦¬ì—ì„œ ì‹¤í–‰ë˜ì–´ ê°„ë‹¨í•©ë‹ˆë‹¤)
    client = chromadb.Client()

    # 'pdf_collection' ì´ë¼ëŠ” ì´ë¦„ì˜ ì»¬ë ‰ì…˜(ë°ì´í„° ì €ì¥ ê³µê°„)ì„ ë§Œë“­ë‹ˆë‹¤.
    # ë§Œì•½ ì´ë¯¸ ìˆë‹¤ë©´ ê¸°ì¡´ ê²ƒì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    collection = client.get_or_create_collection(name="pdf_collection")

    # ê° ì²­í¬ì— ëŒ€í•´ ê³ ìœ  IDë¥¼ ìƒì„±í•˜ê³  ì„ë² ë”©(ë²¡í„° ë³€í™˜)í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.
    for i, chunk in enumerate(text_chunks):
        collection.add(
            embeddings=[model.encode(chunk).tolist()], # ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜
            documents=[chunk], # ì›ë¬¸ í…ìŠ¤íŠ¸ ì €ì¥
            ids=[str(uuid.uuid4())] # ê³ ìœ í•œ ID ë¶€ì—¬
        )
    return collection, model

# ì§ˆë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì²­í¬ë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ëŠ” í•¨ìˆ˜
def search_similar_chunks(collection, model, user_question):
    # ì‚¬ìš©ì ì§ˆë¬¸ë„ ë™ì¼í•œ ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    question_embedding = model.encode(user_question).tolist()
    
    # DBì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ì²­í¬ 3ê°œë¥¼ ì°¾ìŠµë‹ˆë‹¤. (n_results=3)
    results = collection.query(
        query_embeddings=[question_embedding],
        n_results=3
    )
    return results['documents'][0] # ìœ ì‚¬í•œ ì²­í¬ì˜ ì›ë¬¸ í…ìŠ¤íŠ¸ë“¤ì„ ë°˜í™˜

# ìƒì„±í˜• AIì—ê²Œ ë‹µë³€ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜
def get_ai_answer(context, question, api_key):
    # Potens.ai API ì—”ë“œí¬ì¸íŠ¸ì™€ í—¤ë” ì •ë³´
    url = "https://ai.potens.ai/api/chat"
    headers = {
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {api_key}'
    }

    # *** ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ***
    # AIê°€ ë‹µë³€ì„ ì§€ì–´ë‚´ì§€ ì•Šê³ , ë°˜ë“œì‹œ ì£¼ì–´ì§„ ë‚´ìš©ì—ì„œ 'ë°œì·Œ'í•˜ë„ë¡ ê°•ì œí•˜ëŠ” ëª…ë ¹
    prompt = f"""
    ë‹¹ì‹ ì€ ì˜¤ì§ ì£¼ì–´ì§„ 'ë¬¸ì„œ ë‚´ìš©' ì•ˆì—ì„œë§Œ ì •ë³´ë¥¼ ì°¾ì•„ì„œ ë‹µë³€í•´ì•¼ í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

    [ì§€ì‹œì‚¬í•­]
    1. ì‚¬ìš©ìì˜ 'ì§ˆë¬¸'ì— ëŒ€í•œ ë‹µë³€ì„ ì•„ë˜ 'ë¬¸ì„œ ë‚´ìš©'ì—ì„œ ì°¾ìœ¼ì‹­ì‹œì˜¤.
    2. ë‹µë³€ì€ ë°˜ë“œì‹œ 'ë¬¸ì„œ ë‚´ìš©'ì— ìˆëŠ” ë¬¸ì¥ì´ë‚˜ ë¬¸ë‹¨ì„ **ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.**
    3. ì ˆëŒ€ ë‚´ìš©ì„ ìš”ì•½í•˜ê±°ë‚˜, ë‹¤ë¥¸ ë‹¨ì–´ë¡œ ë°”ê¾¸ê±°ë‚˜, ìƒˆë¡œìš´ ë¬¸ì¥ì„ ë§Œë“¤ì§€ ë§ˆì‹­ì‹œì˜¤.
    4. ë§Œì•½ 'ë¬¸ì„œ ë‚´ìš©'ì—ì„œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, ë‹¤ë¥¸ ì–´ë–¤ ë§ë„ í•˜ì§€ ë§ê³  ì˜¤ì§ "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ" ì´ë¼ê³ ë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.

    [ë¬¸ì„œ ë‚´ìš©]
    {context}

    [ì§ˆë¬¸]
    {question}

    [ë‹µë³€]
    """

    data = {"prompt": prompt}

    # APIì— ìš”ì²­ ë³´ë‚´ê¸°
    response = requests.post(url, headers=headers, json=data)
    
    # ì‘ë‹µ ê²°ê³¼ ì²˜ë¦¬
    if response.status_code == 200:
        return response.json().get("choices")[0].get("message").get("content")
    else:
        return f"API í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {response.status_code} - {response.text}"


# --- 2. Streamlit ì›¹ ì•± í™”ë©´ êµ¬ì„± ---

def main():
    st.set_page_config(page_title="ë§ì¶¤í˜• ë¬¸ì„œ ë¶„ì„ AI íˆ´", page_icon="ğŸ¤–")
    st.header("ğŸ“„ ë¬¸ì„œ ê¸°ë°˜ Q&A ì‹œìŠ¤í…œ")
    st.write("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³ , ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
    
    # API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì—ì„œ ì…ë ¥ë°›ìŠµë‹ˆë‹¤.
    # st.secretsë¥¼ ì‚¬ìš©í•´ ë°°í¬ í™˜ê²½ì—ì„œëŠ” ì•ˆì „í•˜ê²Œ í‚¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
    try:
        # Streamlit í´ë¼ìš°ë“œì— ë°°í¬ëœ ê²½ìš° secretsì—ì„œ í‚¤ë¥¼ ê°€ì ¸ì˜´
        api_key = st.secrets["POTENS_API_KEY"]
    except:
        # ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê±°ë‚˜ secrets ì„¤ì •ì´ ì—†ëŠ” ê²½ìš° ì‚¬ìš©ì ì…ë ¥ì„ ë°›ìŒ
        api_key = st.sidebar.text_input("Potens.ai API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", type="password")

    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_files = st.file_uploader("ë¶„ì„í•  PDF íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.", type="pdf", accept_multiple_files=True)

    if uploaded_files:
        if st.button("PDF ì²˜ë¦¬ ë° ë¶„ì„ ì¤€ë¹„"):
            with st.spinner("PDF ë¬¸ì„œë¥¼ ì½ê³  ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                # 1. PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                raw_text = get_pdf_text(uploaded_files)
                
                # 2. í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
                text_chunks = get_text_chunks(raw_text)
                
                # 3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ì €ì¥ (ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ì—¬ ì¬ì‚¬ìš©)
                st.session_state.vectorstore, st.session_state.model = get_vectorstore(text_chunks)
                
                st.success("ë¶„ì„ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ì•„ë˜ì—ì„œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")

    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    if 'vectorstore' in st.session_state: # ë¶„ì„ ì¤€ë¹„ê°€ ì™„ë£Œë˜ì—ˆì„ ë•Œë§Œ ì§ˆë¬¸ì°½ í‘œì‹œ
        user_question = st.text_input("ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”:")

        if user_question:
            if not api_key:
                st.warning("Potens.ai API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                    # 4. ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê°(ì²­í¬) ê²€ìƒ‰
                    similar_chunks = search_similar_chunks(st.session_state.vectorstore, st.session_state.model, user_question)
                    
                    # 5. ê²€ìƒ‰ëœ ì²­í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ AIì—ê²Œ ì •í™•í•œ ë‹µë³€ ìš”ì²­
                    context = "\n\n---\n\n".join(similar_chunks)
                    answer = get_ai_answer(context, user_question, api_key)
                    
                    # 6. ê²°ê³¼ ì¶œë ¥
                    st.write("### AI ë‹µë³€:")
                    st.info(answer)
                    
                    with st.expander("AIê°€ ë‹µë³€ ê·¼ê±°ë¡œ ì°¸ê³ í•œ ì›ë¬¸ ë‚´ìš© ë³´ê¸°"):
                        st.write(context.replace("\n", "\n\n"))


if __name__ == '__main__':
    main()
