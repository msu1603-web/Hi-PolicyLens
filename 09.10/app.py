import os, json
import streamlit as st
import pandas as pd

from llm_client import LLMClient
from retriever_client import RetrieverClient
from prompts import SYSTEM_POLICY, USER_QA_TEMPLATE, USER_DIFF_TEMPLATE, CRITIC_TEMPLATE

st.set_page_config(page_title="ì‹ ì¬ìƒ ì •ì±…Â·ê·œì œ ì›ë¬¸ ì¸ìš© ê²€ìƒ‰", layout="wide")
st.title("ğŸ” ì‹ ì¬ìƒì—ë„ˆì§€ ì •ì±…Â·ê·œì œ â€” ì›ë¬¸ ì¸ìš© ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰")

with st.sidebar:
    st.subheader("âš™ï¸ ì„¤ì •")
    base_url = st.text_input("LLM Base URL", st.secrets.get("POTENS_BASE_URL", "https://api.potens.ai"))
    model    = st.text_input("LLM Model", st.secrets.get("POTENS_MODEL", "claude-4-sonnet"))
    retriever_url = st.text_input("Retriever Base URL", st.secrets.get("RETRIEVER_BASE_URL", ""))
    top_k = st.slider("ê²€ìƒ‰ Top-K", 4, 16, 8, 1)
    do_critic = st.checkbox("2ì°¨ ê²€ì¦(Critic) ì‚¬ìš©", value=True)
    st.caption("ğŸ”’ API í‚¤ëŠ” .streamlit/secrets.tomlì—ë§Œ ë³´ê´€í•˜ì„¸ìš”. ê¹ƒí—ˆë¸Œì— ì˜¬ë¦¬ì§€ ë§ˆì„¸ìš”.")

if "history" not in st.session_state:
    st.session_state.history = []  # [{role, content, is_diff}]

mode = st.radio("ëª¨ë“œ", ["ì¼ë°˜ ì§ˆì˜", "ë¹„êµ ì§ˆì˜"], horizontal=True)
query = st.chat_input("ìì—°ì–´ë¡œ ì§ˆë¬¸í•˜ì„¸ìš”. (ì˜ˆ: íƒœì–‘ê´‘ ë³´ì¡°ê¸ˆ ì •ì±… ë³€í™” ì•Œë ¤ì¤˜)")

def format_context(chunks):
    if not chunks: return "(ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ)"
    blocks = []
    for c in chunks:
        hdr = f"[{c['doc_id']} p.{c.get('page_start','?')}-{c.get('page_end','?')} lines {c.get('line_start','?')}-{c.get('line_end','?')}]"
        blocks.append(hdr + "\n" + c["text"])
    return "\n\n---\n\n".join(blocks)

def ensure_json(txt):
    s = txt.find("{"); e = txt.rfind("}")
    return txt[s:e+1] if s>=0 and e>s else txt

def render_json_answer(data, is_diff=False):
    st.subheader("ìš”ì•½ ë‹µë³€")
    st.write(data.get("answer", "(answer ì—†ìŒ)"))

    if "timeline" in data:
        st.subheader("ë³€í™” íƒ€ì„ë¼ì¸")
        df = pd.DataFrame(data.get("timeline", []))
        if not df.empty: st.dataframe(df, use_container_width=True)

    if is_diff:
        st.subheader("ì°¨ì´ í‘œ (diff_table)")
        ddf = pd.DataFrame(data.get("diff_table", []))
        if not ddf.empty: st.dataframe(ddf, use_container_width=True)
        st.subheader("ëˆ„ë½/ë¶ˆí™•ì‹¤")
        st.write(data.get("missing_info", "(ì—†ìŒ)"))

    st.subheader("ê·¼ê±° ì¸ìš©(ì›ë¬¸ ê·¸ëŒ€ë¡œ)")
    qdf = pd.DataFrame(data.get("quotes", []))
    if not qdf.empty: st.dataframe(qdf, use_container_width=True)

# ê³¼ê±° ëŒ€í™” ì¶œë ¥
for turn in st.session_state.history:
    with st.chat_message(turn["role"]):
        if turn["role"] == "assistant" and isinstance(turn["content"], dict):
            render_json_answer(turn["content"], turn.get("is_diff", False))
        else:
            st.write(turn["content"])

if query:
    st.session_state.history.append({"role":"user","content":query})
    with st.chat_message("user"): st.write(query)

    # 1) ê²€ìƒ‰
    retriever = RetrieverClient(base_url=retriever_url)
    chunks = retriever.search(query, k=top_k)
    context = format_context(chunks)

    # 2) í”„ë¡¬í”„íŠ¸
    if mode == "ì¼ë°˜ ì§ˆì˜":
        user_prompt = USER_QA_TEMPLATE.format(question=query, context=context, k=top_k)
        is_diff = False
    else:
        user_prompt = USER_DIFF_TEMPLATE.format(question=query, context=context, k=top_k)
        is_diff = True

    # 3) LLM í˜¸ì¶œ
    llm = LLMClient(base_url=base_url, model=model)
    raw = llm.chat_json(SYSTEM_POLICY, user_prompt, temperature=0.2)
    raw_json = ensure_json(raw)

    # 4) íŒŒì‹±
    try:
        data = json.loads(raw_json)
    except Exception:
        data = {"answer":"JSON íŒŒì‹± ì‹¤íŒ¨. ëª¨ë¸ ì‘ë‹µ ì›ë¬¸ì„ í™•ì¸í•˜ì„¸ìš”.", "quotes":[], "raw":raw}

    # 5) Critic (ì„ íƒ)
    if do_critic:
        critic_user = CRITIC_TEMPLATE.format(context=context, model_json=json.dumps(data, ensure_ascii=False))
        critic_raw = llm.chat_json("ë‹¹ì‹ ì€ JSON ê°ì‚¬ì§€ëŠ¥ì…ë‹ˆë‹¤. ì¶œë ¥ì€ JSONë§Œ.", critic_user, temperature=0.0)
        cjson = ensure_json(critic_raw)
        try:
            judge = json.loads(cjson)
            if not judge.get("is_valid", True) and judge.get("final"):
                data = judge["final"]
                st.info("ğŸ§ª Critic ë³´ì • ì ìš©")
        except Exception:
            pass

    # 6) ì¶œë ¥ & ê¸°ë¡
    with st.chat_message("assistant"):
        render_json_answer(data, is_diff=is_diff)
    st.session_state.history.append({"role":"assistant","content":data,"is_diff":is_diff})
